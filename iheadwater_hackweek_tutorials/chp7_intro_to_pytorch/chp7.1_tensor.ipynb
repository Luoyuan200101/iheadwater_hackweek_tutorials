{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c408032-c93e-4137-a98e-957767d22c9d",
   "metadata": {},
   "source": [
    "# PyTorch中的Tensor基础\n",
    "\n",
    "PyTorch的tensor和Numpy的Array，Pandas的Series和Dataframe类似，是了解应用这些代码库的基础，这里首先简单快速地了解Tensor及其在PyTorch的作用。\n",
    "\n",
    "主要参考：\n",
    "\n",
    "- TENSORS\n",
    "- Speed Up your Algorithms Part 1 — PyTorch\n",
    "- PyTorch 101, Part 1: Understanding Graphs, Automatic Differentiation and Autograd\n",
    "\n",
    "## 快速了解Tensor\n",
    "pytorch作为NumPy的替代品，可以利用GPU的性能进行计算；可作为一个高灵活性、速度快的深度学习平台。\n",
    "\n",
    "Tensor（张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。因此经常看到把numpy的数组包装为tensor再运算。tensor的操作和numpy中的数组操作类似，不再赘述，详见官网。下面列举一些简单例子。首先pytorch的导入是import torch，因为torch一直都是那个torch，一开始是别的语言写的，现在在python下，所以就叫pytorch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126a7c8f-4e05-4f70-8347-a08b2aaeefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c25dc-a27f-473e-98a3-52cdf01369e3",
   "metadata": {},
   "source": [
    "Tensor是pytorch的基本数据类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abcfd79-d6ca-4589-9f6a-2e6b92bb133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5)\n",
    "# 如果想要从tensor中获取到长度的int数据\n",
    "type(list(x.shape)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fa9789-b7d8-42c7-872d-7c269251b3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3628e+38,  4.5726e-41, -1.3628e+38],\n",
       "        [ 4.5726e-41,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.8174e+31,  1.8788e+31,  1.7220e+22],\n",
       "        [ 2.1715e-18,  8.5491e+20,  4.3205e-05]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建一个 5x3 的矩阵, 未初始化的:\n",
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2952f5-74a0-4793-8112-4a1b42d96a4b",
   "metadata": {},
   "source": [
    "由此可见，PyTorch提供了Tensor，其在概念上与 numpy 数组相同，也是一个n维数组, 不过PyTorch 提供了很多能在这些 Tensor 上操作的函数\n",
    "\n",
    "而且任何numpy 数组的操作都可以在 PyTorch Tensor 上开展。不像 numpy, PyTorch Tensor 只需将其转换为新的数据类型，就可以利用 GPU 加速他们的数字计算。\n",
    "\n",
    "此外，tensor还拥有autograd自动求导功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f228802-4f21-4c59-a4aa-fdcd33ce6e9a",
   "metadata": {},
   "source": [
    "## autograd自动求导\n",
    "\n",
    "在PyTorch中，所有神经网络的核心是autograd包。autograd 包为张量上的所有操作提供了自动求导机制。它是一个在运行时定义（define-by-run）的框架，这意味着反向传播是根据代码如何运行来决定的，并且每次迭代可以是不同的.\n",
    "\n",
    "torch.Tensor 是这个包的核心类。如果设置它的属性 .requires_grad 为 True，那么它将会追踪对于该张量的所有操作。当完成计算后可以通过调用 .backward()，来自动计算所有的梯度。这个张量的所有梯度将会自动累加到.grad属性.\n",
    "\n",
    "为了阻止跟踪历史，可以使用 with torch.no_grad(): 包裹代码块，在评价模型时这很有用，因为模型可能有有参数 requires_grad=True 的能训练的参数，但是这时候我们不需要梯度。\n",
    "\n",
    "还有一个类对于autograd的实现非常重要：Function。Tensor 和 Function 互相连接生成了一个无圈图(acyclic graph)，它编码了完整的计算历史。每个tensor有 .grad_fn 属性，该属性指向一个创建Tensor的Function。用户创建的tensor的grad_fn 是None，即新建一个tensor，它是没有grad_fn的。\n",
    "\n",
    "如果想计算微分，可以在Tensor上调用.backward()。如果Tensor是一个标量（只含一个数据），就不需要给backward()指定参数，不过当元素较多时，需要制定一个gradient参数，这是一个有匹配shape的tensor。\n",
    "\n",
    "上面这段话还是有点晦涩，所以看例子。先构造一个tensor，设置requires_grad=True来跟踪计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b228503-3318-4a2a-a21a-a728fca11f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(2, 2, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b787b5-63eb-45ca-bd57-aaf48aec0d9a",
   "metadata": {},
   "source": [
    "tensor可以做计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36087718-a663-4a85-8a03-5c9c6df7808f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a78baa-9b47-4f0b-803f-e9162b082517",
   "metadata": {},
   "source": [
    "注意y是一个计算的结果，所以如前面文字所述，它有grad_fn属性，指向创建它的Function。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d936d1-e3f9-4539-8333-3bf136c63c80",
   "metadata": {},
   "source": [
    "综上：\n",
    "\n",
    "- 在PyTorch中，torch.Tensor是存储和变换数据的主要工具。\n",
    "- Tensor与Numpy的多维数组非常相似。\n",
    "- Tensor还提供了GPU计算和自动求梯度等更多功能，这些使Tensor更适合深度学习。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tutorial)",
   "language": "python",
   "name": "tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
